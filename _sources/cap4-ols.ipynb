{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a316953",
   "metadata": {},
   "source": [
    "# Capítulo 4 · Formulación matricial del modelo OLS\n",
    "\n",
    "**Objetivo:** derivar y aplicar el estimador matricial de Mínimos Cuadrados Ordinarios (OLS)\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^\\top X)^{-1}X^\\top y\n",
    "$$\n",
    "\n",
    "usando **las variables candidatas** seleccionadas en el Capítulo 3 y comparar con `statsmodels.OLS`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312d522",
   "metadata": {},
   "source": [
    "## 4.1 Datos y construcción de \\(X\\) y \\(y\\)\n",
    "\n",
    "En este capítulo construiremos \\(X\\) (predictores) y \\(y\\) (respuesta) a partir del dataset *Ames Housing*.\n",
    "Tomamos como objetivo $ y = \\texttt{SalePrice} $ y elegimos **hasta 12 variables candidatas** con alta correlación y baja colinealidad (según el criterio del Cap. 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13c04e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Overall Qual',\n",
       "  'Gr Liv Area',\n",
       "  'Garage Cars',\n",
       "  'Total Bsmt SF',\n",
       "  '1st Flr SF',\n",
       "  'Year Built',\n",
       "  'Full Bath',\n",
       "  'Year Remod/Add',\n",
       "  'Garage Yr Blt',\n",
       "  'Mas Vnr Area',\n",
       "  'TotRms AbvGrd',\n",
       "  'Fireplaces'],\n",
       " (2748, 13),\n",
       " (2748, 1))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Localiza el CSV (compatible con tu estructura de proyecto)\n",
    "CANDIDATE_PATHS = [Path('data/ames_housing.csv'), Path('AmesHousing.csv')]\n",
    "for p in CANDIDATE_PATHS:\n",
    "    if p.exists():\n",
    "        DATA_PATH = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError('No se encontró data/ames_housing.csv ni AmesHousing.csv')\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Asegurar numérico y eliminar infinitos\n",
    "num_df = df.select_dtypes(include=[np.number]).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Pool por correlación absoluta con el target\n",
    "corr_abs = num_df.corr(numeric_only=True)[target].dropna().abs().sort_values(ascending=False)\n",
    "\n",
    "# Empezamos con top 15 (excluyendo el propio SalePrice) y filtramos por colinealidad > 0.85\n",
    "pool = [c for c in corr_abs.index if c != target][:15]\n",
    "\n",
    "sel = []\n",
    "for v in pool:\n",
    "    if not sel:\n",
    "        sel.append(v)\n",
    "        continue\n",
    "    ok = True\n",
    "    for u in sel:\n",
    "        r = abs(num_df[[v, u]].dropna().corr().iloc[0,1])\n",
    "        if r > 0.85:\n",
    "            ok = False\n",
    "            break\n",
    "    if ok:\n",
    "        sel.append(v)\n",
    "    if len(sel) >= 12:\n",
    "        break\n",
    "\n",
    "# Construcción de matrices con intercepto\n",
    "data = num_df[[target] + sel].dropna()\n",
    "y = data[target].values.reshape(-1, 1)\n",
    "X = data[sel].values\n",
    "X = np.c_[np.ones((X.shape[0], 1)), X]  # intercepto\n",
    "\n",
    "sel, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e21feb",
   "metadata": {},
   "source": [
    "El vector de variables elegidas `sel` es el conjunto de **candidatas** para este capítulo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f7ddc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.2 Derivación del estimador OLS\n",
    "\n",
    "Sea el problema de mínimos cuadrados: minimizar  \n",
    "\n",
    "$$\n",
    "S(\\beta) = \\|y - X\\beta\\|^2\n",
    "$$  \n",
    "\n",
    "La condición de primer orden (ecuaciones normales) es  \n",
    "\n",
    "$$\n",
    "X^\\top X\\,\\hat{\\beta} = X^\\top y\n",
    "$$  \n",
    "\n",
    "Si \\( X^\\top X \\) es invertible (pleno rango), entonces  \n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y\n",
    "$$  \n",
    "\n",
    "> **Invertibilidad:** Se requiere $ \\operatorname{rango}(X) = p $ (columnas linealmente independientes).  \n",
    "> Con intercepto, $ p = $ número de predictores + 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca8fb8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.3 Cálculo numérico manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6686e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(13),\n",
       " np.float64(319660665340.50195),\n",
       " array([-1.25777520e+06,  1.87534463e+04,  4.91830698e+01,  1.38468260e+04,\n",
       "         2.22139198e+01]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo manual de beta_hat\n",
    "XtX = X.T @ X\n",
    "Xty = X.T @ y\n",
    "\n",
    "# Comprobaciones de rango y número de condición\n",
    "rank = np.linalg.matrix_rank(XtX)\n",
    "cond = np.linalg.cond(XtX)\n",
    "\n",
    "beta_hat = np.linalg.inv(XtX) @ Xty\n",
    "\n",
    "rank, cond, beta_hat[:5].ravel()  # mostramos primeras 5 betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cc968",
   "metadata": {},
   "source": [
    "### Predicciones, residuos y suma de cuadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65fc3625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 13, 3480471313588.8584, 1272567207.8935497)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = X @ beta_hat\n",
    "res  = y - yhat\n",
    "SSR = float(np.sum(res**2))  # residual sum of squares\n",
    "n, p = X.shape\n",
    "sigma2_hat = SSR / (n - p)\n",
    "\n",
    "n, p, SSR, sigma2_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932e11a",
   "metadata": {},
   "source": [
    "### Varianzas de \\(\\hat{\\beta}\\) y errores estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d38208b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.41667931e+04, 8.12249493e+02, 3.01464083e+00, 1.51693822e+03,\n",
       "       2.81210621e+00])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Var(beta_hat) = sigma^2 * (X'X)^{-1}\n",
    "var_beta = sigma2_hat * np.linalg.inv(XtX)\n",
    "se_beta = np.sqrt(np.diag(var_beta)).reshape(-1,1)\n",
    "\n",
    "se_beta[:5].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0346e35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.4 Comparación con `statsmodels.OLS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4da5d488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.800\n",
      "Model:                            OLS   Adj. R-squared:                  0.799\n",
      "Method:                 Least Squares   F-statistic:                     909.9\n",
      "Date:                Tue, 11 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        00:56:18   Log-Likelihood:                -32698.\n",
      "No. Observations:                2748   AIC:                         6.542e+04\n",
      "Df Residuals:                    2735   BIC:                         6.550e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.258e+06   9.42e+04    -13.357      0.000   -1.44e+06   -1.07e+06\n",
      "x1          1.875e+04    812.249     23.088      0.000    1.72e+04    2.03e+04\n",
      "x2            49.1831      3.015     16.315      0.000      43.272      55.094\n",
      "x3          1.385e+04   1516.938      9.128      0.000    1.09e+04    1.68e+04\n",
      "x4            22.2139      2.812      7.899      0.000      16.700      27.728\n",
      "x5            12.1134      3.212      3.772      0.000       5.816      18.411\n",
      "x6           216.4772     46.743      4.631      0.000     124.822     308.132\n",
      "x7         -7950.1848   1836.455     -4.329      0.000   -1.16e+04   -4349.205\n",
      "x8           376.3075     47.104      7.989      0.000     283.945     468.670\n",
      "x9            11.9275     55.913      0.213      0.831     -97.709     121.564\n",
      "x10           35.7916      4.369      8.192      0.000      27.224      44.359\n",
      "x11         -868.7341    766.437     -1.133      0.257   -2371.588     634.120\n",
      "x12         8697.6657   1236.964      7.031      0.000    6272.187    1.11e+04\n",
      "==============================================================================\n",
      "Omnibus:                     1164.902   Durbin-Watson:                   1.534\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           134958.524\n",
      "Skew:                          -1.007   Prob(JB):                         0.00\n",
      "Kurtosis:                      37.273   Cond. No.                     5.65e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.65e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Con statsmodels (agrega intercepto)\n",
    "y_sm = data[target].values\n",
    "X_sm = sm.add_constant(data[sel].values, has_constant='add')\n",
    "\n",
    "ols = sm.OLS(y_sm, X_sm).fit()\n",
    "\n",
    "print(ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435d097",
   "metadata": {},
   "source": [
    "> **Coincidencia:** Los coeficientes, errores estándar y métricas (R², SSR) deben coincidir con los obtenidos manualmente (salvo diferencias de redondeo).  \n",
    "> Verifica especialmente `params` y `bse` frente a `beta_hat` y `se_beta` calculados arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d545b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.5 Discusión: invertibilidad y significado de cada término\n",
    "\n",
    "- \\( X^\\top X \\) **singular** → ocurre con multicolinealidad perfecta (columnas duplicadas o combinación lineal exacta).  \n",
    "- \\( \\kappa(X^\\top X) = \\text{condición} \\) **alta** → problemas de inestabilidad numérica; considerar eliminar predictores redundantes o regularización.  \n",
    "- **Interpretación:**  \n",
    "  - Intercepto: precio esperado cuando los predictores valen cero (interpretar con cautela).  \n",
    "  - Pendientes: cambio esperado en `SalePrice` por unidad del predictor, manteniendo los demás constantes.\n",
    "\n",
    "> Para diagnóstico adicional, considera calcular **VIF** y estandarizar predictores antes del ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a49fb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.6 Key takeaways\n",
    "\n",
    "- El estimador matricial  $$ (X^\\top X)^{-1}X^\\top y $$  coincide con `statsmodels.OLS`.  \n",
    "- La **invertibilidad** depende del rango de \\(X\\); la colinealidad alta puede inflar varianzas y volver inestable la estimación.  \n",
    "- Usar variables **candidatas** reduce colinealidad y mejora interpretabilidad del modelo base que se ampliará en los siguientes capítulos.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
